---
title: "Transcriptomal Changes in MSCs Following Exposure to Spinal Cord"
author: "Ramil Hakim"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document:
    theme: flatly
    toc: true
    number_sections: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Executive Summary



***

# Project Description

**Hypothesis:** *The transcriptome of bone marrow derived mesenchymal stem cells (MSCs) transplanted into a spinal cord injury environment is altered as compared to MSCs transplanted into uninjured spinal cord.*

**Experimental setup & sequencing:** mCherry+MSCs were transplanted into injured (75 kdyn contusion injury, 24h post SCI) or uninjured spinal cord using a glas capillary pipette. C57BL/6J female mice were utilized. At 7 days post transplantation the mCherry+MSCs were collected using FACS. FACS of MSCs from injured spinal cord was performed using injured spinal cord as reference (i.e. negative gate setting). FACS of MSCs from uninjured spinal cord was performed using uninjured spinal cord as reference. Total RNA, digested of DNase, was isolated and sequenced (125 cycles paired-end) in two lane using the HiSeq2500 system and v4 sequencing chemistry (Illumina Inc.) performed by the SNP&SEQ Technology Platform (Stockholm, Sweden). Libraries were prepared using SMARTer Stranded Total RNA-Seq Kit - Pico Input Mammalian (Takara).

**Data analysis:** Data was analyed using the edgeR and limma packages (both available through bioconductor.org) using R version 3.4.4 (*Someone to Lean On*). Two additional key packages used were ggplot2 and data.table.    

***

# Data Overview

```{r echo=F, warning=F, message=F, error=F}
#1. Installing packages
# source("https://bioconductor.org/biocLite.R")
# biocLite("limma")

# source("https://bioconductor.org/biocLite.R")
# biocLite("edgeR")

#install.packages("data.table")
#install.packages("ggplot2")
#install.packages("cowplot")
#install.packages("RColorBrewer")
#install.packages("gplots")
#install.packages("pvclust")
#install.packages("VennDiagram")
# install.packages("rafalib")
#install.packages("grid")
#install.packages("colorspace")
#install.packages("ellipse")
#install.packages("ggrepel")
#install.packages("rafalib")
#install.packages("boot")
#install.packages("pvclust")
#install.packages("RCurl")
#install.packages("XML")
#install.packages("xml2")
#install.packages("caret")
#install.packages("Rtsne")
#install.packages("plot3D")
#install.packages("EMCluster")
#install.packages("MeanShift")
#install.packages("apcluster")
#install.packages("e1071")
#install.packages("circlize")

#Installation guide for ggraph
  #sudo apt-get -y install libcurl4-gnutls-dev
  #sudo apt-get -y install libssl-dev
  #install.packages("devtools")
  #sudo apt-get install libudunits2-dev
  # install.packages('udunits2', type = "source",
  #                    configure.args=c('--with-udunits2-lib=/home/ramhak/R/x86_64-pc-linux-gnu-library/3.4'))
  #devtools::install_github("thomasp85/ggraph", dependencies=TRUE, force=T)
  #devtools::install_github('tidyverse/ggplot2', dependencies=T, force=T) #Get the development version of ggplot2
  #library(ggplot2)

#2. Attaching packages
library(limma)
library(edgeR)
library(Mus.musculus)

library(data.table)
library(ggplot2)
library(cowplot)
library(gridExtra)
library(grid)

library(colorspace)
library(RColorBrewer)
library(gplots)
library(VennDiagram)
library(ellipse)
library(plot3D)
library(ggrepel)
library(rafalib)

library(boot)
library(pvclust)

library(knitr)
library(pander)

library(RCurl)
library(XML)
library(xml2)

library(caret)
library(Rtsne)

library(MASS)
library(mda)
library(kernlab)
library(EMCluster)
library(MeanShift)
library(apcluster)
library(e1071)

library(ggraph)
library(igraph)
library(ape)
library(circlize)

#Clearing workspace
rm(list=ls())

#Importing function for legend collection from ggplot 
source("/home/ramhak/Dropbox/PHD/PAPER I/R_v2/Function_directory/get_legend.R")
```

```{r echo=F, warning=F, message=F, error=F}
############## IMPORTING DATA, ANNOTATING GENES & ORGANISING META DATA #############
```

```{r echo=F, warning=F, message=F, error=F}
#1. Importing read count matrix
DT_read_count <- fread("merged_gene_counts.txt", header=T)
#2. Adjusting column names 
names(DT_read_count) <- c(names(DT_read_count)[1], do.call(rbind, lapply(names(DT_read_count)[2:length(names(DT_read_count))], function(col_name){substr(col_name, 7, 9)})))
#3. Retrieving gene annotations (SYMBOL) based on ENSEMBL_ID
gene_annotations <- suppressMessages(data.table(OrganismDbi::select(Mus.musculus, keys=DT_read_count[,as.character(ENSEMBL_ID)], columns="SYMBOL", keytype = "ENSEMBL")))
#4. Removing duplicates in retrieved annotations
gene_annotations <- gene_annotations[!duplicated(ENSEMBL)]
#5. Merging gene annotations with read_count_matrix 
DT_read_count <- merge(DT_read_count, gene_annotations, by.x="ENSEMBL_ID", by.y="ENSEMBL")
DT_read_count <- setcolorder(DT_read_count, c(1,24,2:23))
#6. Importing meta_data
DT_meta_data <- fread("meta_data.csv")
DT_meta_data <- DT_meta_data[Status=="Included", !c("RH.index", "Status")]
names(DT_meta_data) <- c("ID", "group")
#7. Adding library size (=column sums)
DT_meta_data <- DT_meta_data[,library.size:=colSums(DT_read_count[,-(1:2)])]
#8. Adding normalisation factor (=1 initially)
DT_meta_data <- DT_meta_data[,norm.factor:=1]
#9. Defining factor variables
factor_vars <- c("ID", "group")
DT_meta_data[,factor_vars] <- DT_meta_data[,lapply(.SD, factor), .SDcols=factor_vars]

###SECTION OUTPUT
#Table with dataset characteristics
pander(data.table(Characteristic=c("Samples (n):","Groups (n):","Unique ENSEMBL IDs (n):"), Value= c(ncol(DT_read_count[,-(1:2)]), length(unique(DT_meta_data[,group])), nrow(DT_read_count))), justify=c("left", "left"))

```

***

# Data Pre-Processing

## *Transforming from raw scale and removing lowly expressed genes*

**Background:** The expression of a gene must reach a certain threshold for it to be translated into a protein. Translation into a protein is a prerequiste for a gene to have any biological function. Thus, genes with low number of read counts across samples are probably not differentially expressed and should be removed. However, a greater sequencing depth (i.e. a larger library size) will result in a higher read count, thus introducing a bias to the DGE analysis. Therefore, prior to filtering, raw counts are transformed into counts per million (CPM) which accounts for the difference in library size. 

**Transformation:** Raw counts are transformed into CPM by dividing each count with the sum of the column (i.e. the library size) and then multiplying by 1e6. Log-CPM is calculated by taking log2 (raw count + 0.25).

**Filtering:** Lowly expressed genes are removed from the count matrix by filtering. A gene is defined as highly expressed if CPM>1 (i.e. log-CPM>0) for at least three samples. Three samples was chosen since it is equal to the smallest group size (which is equal between groups in this case).   

**Fig 1. Density of log-CPM values pre -and post filtering**

```{r echo=F, warning=F, message=F, error=F, fig.height=4, fig.width=12}
#1. Converting the read count matrix into a log CPM matrix 
DT_lcpm_unfiltered <- data.table(cpm(DT_read_count[,-c(1:2)], log=T, lib.size = colSums(DT_read_count[,-c(1:2)])))
#2. Filtering out lowly expressed genes from read count matrix using log-CPM values
DT_read_count_filtered <- DT_read_count[rowSums(DT_lcpm_unfiltered>0)>=3]
#3. Calculating log CPM matrix using the filtered read count matrix
DT_lcpm <- cpm(DT_read_count_filtered[,-c(1:2)], log=T, lib.size = colSums(DT_read_count_filtered[,-c(1:2)]))
#4. Melting data for plotting
lcpm_unfiltered_plotdata <- suppressWarnings(melt.data.table(data.table(DT_lcpm_unfiltered), variable.name="ID", value.name = "lcpm"))
lcpm_filtered_plotdata <- suppressWarnings(melt.data.table(data.table(DT_lcpm), variable.name="ID", value.name = "lcpm"))

#5. Plotting function (density against log-CPM values)
logCPM_density_plot_function <- function(plot.data, type, legend.type){
  logCPM_density_plot_out <- ggplot(plot.data, aes(x=lcpm, color=ID))+
  geom_line(stat="density", size=1.25)+
  geom_vline(xintercept=0, linetype=2)+

  scale_x_continuous(breaks=seq(-10,16,2), limits=c(-8,16))+
  scale_y_continuous(breaks=seq(0,0.6,0.05), limits=c(0,0.6))+
  scale_color_manual(values=diverge_hcl(22, c=100, l=c(50,90), power=1))+
  annotate(geom="text", x=5, y=0.55, label=type, size=7.5, alpha=0.6)+
  annotate(geom="text", x=5, y=0.5, label=paste("Genes (n):", toString(unique(plot.data[,.N, by="ID"][,N]))), fontface=2, size=4)+
  theme(legend.position=legend.type, axis.title=element_blank())
  
  if(type=="RAW"){
    logCPM_density_plot_out <- logCPM_density_plot_out + annotate(geom="text", x=-8, y=0.6, label="A", size=7.5, fontface=2) 
  } else if(type=="FILTERED"){
    logCPM_density_plot_out <- logCPM_density_plot_out + annotate(geom="text", x=-8, y=0.6, label="B", size=7.5, fontface=2)
  }

  return(logCPM_density_plot_out)  
}

density_raw_plot <- logCPM_density_plot_function(lcpm_unfiltered_plotdata, "RAW","right")
density_legend <- get_legend(density_raw_plot)
density_raw_plot <- logCPM_density_plot_function(lcpm_unfiltered_plotdata, "RAW","none")
density_filtered_plot <- logCPM_density_plot_function(lcpm_filtered_plotdata, "FILTERED","none")

###SECTION OUTPUT
grid.arrange(density_raw_plot, density_filtered_plot, ncol=2, widths=c(3,3), bottom=textGrob("log-CPM", gp=gpar(fontsize=17, fontface="bold")), left=textGrob("Density", gp=gpar(fontsize=17, fontface="bold"), rot=90))

```

**Fig 1.** _Figure reports the density of log-CPM for every sample (by color) pre -and post filtering out lowly expressed genes. Filtering is conducted using log-CPM values. Approximately 1/3 of the genes remain after filtering. Vertical dashed line represents the cut off (log-CPM=0, CPM=1). The figure shows a distinct shift of the density from below the threshold (Fig 1A) to above the threshold (Fig 1B)._  

***

## *Normalizing gene expression distributions*

**Background:** The read count is affected by: 1) the gene expression and 2) the sequencing depth. The sequencing depth equals the library size. The library size is defined as the sum of counts for each sample (i.e. column sum). The counts per sample represent the relative abundance of each gene. Highly expressed genes can consume a substantial proportion of the library size thus making the other genes seem underexpressed. Therefore, normalization is conducted in order to ensure that the distribution of the expression is similar for each sample. All samples should have a smiliar range and distribution of expression (log-CPM). 

**Normalization:** Scaling factors are calculated using the trimmed mean of M-values (TMM) algorithm. The algorithm finds a set of scaling factors which minimizes the log-fold change between the samples. Scaling factors >1 downscale the counts while scaling factors <1 scale the counts upwards. The effective library size is then obtained by taking the product of the original library size and the scaling factor for each sample respectively.  

```{r echo=F, warning=F, message=F, error=F}
############## NORMALISING GENE EXPRESSION DISTRIBUTIONS #############
```

```{r echo=F, warning=F, message=F, error=F}
#1. Calculating normalization factors using TMM algorithm and adding to meta_data
DT_meta_data <- DT_meta_data[,norm.factor.tmm:=calcNormFactors(DT_read_count_filtered[,-(1:2)], method = "TMM")]
#2. Calculating adjusted library sizes in meta_data
DT_meta_data <- DT_meta_data[,effective.library.size:=library.size*norm.factor.tmm]
```

**Fig 2. Distribution of log-CPM values pre -and post normalization**

```{r echo=F, warning=F, message=F, error=F, fig.height=5, fig.width=12}
#1. Calculating log2 of read_count_matrix with unadjusted and adjusted library size respectively
lcpm_temp_notNormalised <- cpm(DT_read_count_filtered[,-(1:2)], log=T, lib.size = DT_meta_data[,library.size])
lcpm_temp <- cpm(DT_read_count_filtered[,-(1:2)], log=T, lib.size = DT_meta_data[,effective.library.size])
#2. Adding id columns and converting into data.table
DT_lcpm_notNormalised <- data.table(DT_read_count_filtered[,c(1:2)], lcpm_temp_notNormalised)
DT_lcpm <- data.table(DT_read_count_filtered[,c(1:2)], lcpm_temp)
#3. Melting data in order to create plottable data
DT_lcpm_notNormalised_melt <- melt.data.table(DT_lcpm_notNormalised, id.vars=c("ENSEMBL_ID", "SYMBOL"), variable.name = "ID")
DT_lcpm_melt <- melt.data.table(DT_lcpm, id.vars=c("ENSEMBL_ID", "SYMBOL"), variable.name = "ID")
#4. Plotting function for gene expression distribution
log_cpm_distribution_function <- function(dataset, type){
  log_cpm_distribution_plot <- ggplot(dataset, aes(ID, value, color=ID))+
  geom_jitter(DT_lcpm_notNormalised_melt[,.(value=sample(value, 10000)), by="ID"], mapping=aes(ID, value), alpha=0.05)+
  geom_boxplot(size=1, color="black", alpha=0)+

  scale_y_continuous(limits=c(-8,20), breaks=seq(-10,20,2))+
  scale_fill_manual(values=diverge_hcl(22, c=100, l=c(50,90), power=1), name="Sample:")+
  scale_color_manual(values=diverge_hcl(22, c=100, l=c(50,90), power=1), name="Sample:")+
    
  theme(legend.position="none", axis.title=element_blank(), axis.text.x=element_text(size=10, angle=90))+
  annotate("text", x=11.5, y=18, label=type, size=7.5, alpha=0.6)
  
  if(type =="RAW"){
    log_cpm_distribution_plot <- log_cpm_distribution_plot + annotate("text", x=2, y=20, label="A", size=7.5, fontface=2)
  } else if(type=="NORMALIZED"){
    log_cpm_distribution_plot <- log_cpm_distribution_plot + annotate("text", x=2, y=20, label="B", size=7.5, fontface=2)
  }

  return(log_cpm_distribution_plot)
}

###SECTION OUTPUT
grid.arrange(log_cpm_distribution_function(DT_lcpm_notNormalised_melt, "RAW"), log_cpm_distribution_function(DT_lcpm_melt, "NORMALIZED"), ncol=2, bottom=textGrob("Sample", gp=gpar(fontsize=17, fontface="bold")), left=textGrob("log-CPM", gp=gpar(fontsize=17, fontface="bold"), rot=90))

```

**Fig 2.** _Figure reports the distribution of gene expression (log-CPM) for each sample. Fig 2A reports the distribution prior to normalization while Fig 2B reports the distribution following normalization of library sizes using trimmed means of M-values (TMM algorithm). Boxplots are based on all log-CPM values while points represent a random sample of 1e4 observations (due to processing time issues). The difference in the distribution of log-CPM using original and effective library sizes is minor but now adjusted for._

***

```{r echo=F, warning=F, message=F, error=F}
########################################### UNSUPERVISED LEARNING (PCA & tSNE) ############################################
```

# Dimensionality Reduction

Reducing the number of dimensions of a dataset without compromising the information content. Two main approaches: feature selection / linear models and feature extraction. 
Feature selection: find a subset of the original variables.
Feature extraction: transformation from high-dimensional to low-dimensional space. 

* **Principal component analysis (PCA):** 1) The mean of each variable is subtracted to center the data (mean of each column is zero), 2) variance-covariance matrix is calculated, 3) eigenvalues and eigenvectors of the covariance matrix is determined, 4) each (orthogonal) eigenvector is normalized in order to find the unit vector. 

* **t-distributed Stochastic Neighbour Embedding (tSNE):** A non-linear approach. Algorithm has two main steps: 1) probability distribution is constructed on the data such that similar points are likely to be picked and vice versa. 2) Divergence between the distributions is minimized with respect to the location of the points on the map.  

* **Sammon's non-linear mapping:** A non-linear approach. Algorithm minimizes the stress (i.e. the difference between distances between points in the input data and the distances in the configuration). 

* **Multidimensional scaling (MDS):** A non-linear approach. 1) assign observations to arbitrary coordiantes in p-dimensional space, 2) compute euclidian distances among all pairs of points and form the Dhat matrix, 3) compare the Dhat matrix with the input matrix using a stress function (low stress level indicates a good correspondence), 4) repeat proces untill stress cannot be minimized more.     

* **Linear discriminant analysis (LDA):** Similar to PCA and factor analysis. Looks for linear combinations of variables which best explain the data. In addition to finding the component axes which maximizes the variance of the data (as in PCA), LDA also find the axes which maximizes the separation between multiple classes. LDA is supervised and computes the directions (linear discriminants) that represent the axes that maximize the separation between multiple classes. 

* **Singular Value Decomposition (SVD):** The matrix A(mxn) is factorized into a unitary matrix U (mxm), a positive diagnonal matrix (mxn) and a unitary matrix V (nxn).  

* **Factor analysis (maximum likelihood):** 

* **Mixture Discriminant Analysis (MDA):** Extension of linear discriminant analysis. Uses a mixture of Gaussian models as compared to the LDA which uses only one. Models the within group multivariate density of the predictors using a mix of multivariate normal distributions.  

* **Flexible Discriminant Analysis (FDA):** A mixture of linear regression models.

* **Kernel PCA:** Extension of PCA by using kernel methods. The data points are first mapped onto a non-linear feature space, then the PCA is conducted as usual.

**Fig 3. Variance explained by principal components based on the 500 genes with highest variance**

```{r echo=F, warning=F, message=F, error=F, fig.height=6, fig.width=12}
#1. Calculating the variance between samples within each gene
gene_variance <- data.table(DT_lcpm[,c(1:2)], variance=apply(DT_lcpm[,-(1:2)], 1, var))
#2. Selecting the 500 genes with the highest inter-sample variance 
gene_variance_top500 <- gene_variance[order(-variance)][1:500]
#3. Calculating principal components for the genes with highest variance (top 500) from DT_lcpm
setkey(DT_lcpm, ENSEMBL_ID)
DT_principal_comp_raw <- prcomp(t(DT_lcpm[ENSEMBL_ID %in% gene_variance_top500[,ENSEMBL_ID],-(1:2)]))
DT_principal_comp_summary <- data.table(sd=summary(DT_principal_comp_raw)$sdev)
#4. Subsetting data from raw PC-object for plotting
DT_principal_comp <- data.table(ID=factor(rownames(DT_principal_comp_raw$x)), DT_principal_comp_raw$x)
#5. Merging with meta data
DT_principal_comp <- merge(DT_principal_comp, DT_meta_data[,.(ID, group)], by="ID")
#6. Calculating proportion of explained variance for each component
DT_principal_comp_summary <- DT_principal_comp_summary[,var:=sd**2][,var.prop:=var/sum(var)][,var.prop.cumsum:=cumsum(var.prop)]
#7. Plotting function: proportion of variance explained by each component (proportional/cumulative)
PCA_plot_prop.var_function <- function(dataset, yvariable, color){
  explained_var_plot <- ggplot(dataset, aes(1:22, get(yvariable)))+
  geom_bar(stat="identity", fill=brewer.pal(11, "RdBu")[color], alpha=0.9, width=0.7)+
  geom_point(size=4, shape=18)+
  geom_line(linetype=2, size=1.5)+
  geom_text(aes(label=format(round(get(yvariable), 2), digits=2)), vjust=-1, fontface="bold", size=3)+
  
  scale_x_discrete(limits=seq(1,22,1))+
  scale_y_continuous(breaks=seq(0,1,0.1), limits=c(0,1.1))+
  theme(axis.title=element_blank())
  
  if(yvariable=="var.prop"){
    explained_var_plot <- explained_var_plot + annotate(geom="text", x=1, y=1.1, label="A", fontface=2, size=7.5)+ annotate(geom="text", x=11.5, y=1.1, label="PROPORTIONAL", size=6, alpha=0.6)
  } else if(yvariable=="var.prop.cumsum"){
    explained_var_plot <- explained_var_plot + annotate(geom="text", x=1, y=1.1, label="B", fontface=2, size=7.5)+annotate(geom="text", x=11.5, y=1.1, label="CUMULATIVE", size=6, alpha=0.6)
  }
  
  return(explained_var_plot)
}

#8. Selecting the 500 genes with highest variance from the log-CPM matrix
DT_pca_sim <- DT_lcpm[ENSEMBL_ID %in% gene_variance_top500[,ENSEMBL_ID],-(1:2)]
#9. Boostrapping proportion of variance for each principal component   
DT_pca_boot_conf <- boot(DT_pca_sim, function(dataset, b){summary(prcomp(t(dataset[b])))$importance[2,]}, 1000)
#10. Extracting 95 % confidence intervals from bootstrapped data
DT_pca_boot_conf_summary <- suppressWarnings(data.table(do.call(rbind, lapply(1:10, function(column){boot.ci(DT_pca_boot_conf, type="bca", index=column)$bca[(4:5)]}))))
names(DT_pca_boot_conf_summary) <- c("CI.Lower", "CI.Upper")
#11. Converting bootstrapped data into plotable data 
DT_pca_boot_conf_plotdata <- data.table(DT_pca_boot_conf$t)[, 1:10]
names(DT_pca_boot_conf_plotdata) <- names(DT_pca_boot_conf$t0)[1:10]
DT_pca_boot_conf_plotdata <- suppressWarnings(melt.data.table(DT_pca_boot_conf_plotdata, variable.name = "PC.type"))

###SECTION OUTPUT
grid.arrange(PCA_plot_prop.var_function(DT_principal_comp_summary,"var.prop", 1), PCA_plot_prop.var_function(DT_principal_comp_summary,"var.prop.cumsum", 11), ncol=2, bottom=textGrob("Principal component", gp=gpar(fontsize=17, fontface="bold")), left=textGrob("Proportion variance explained", gp=gpar(fontface="bold", fontsize=17), rot=90))

```

**Fig 3.** _Figure reports the proportion variance explained by each principal component. Fig 3A reports the proportional variance explained by each component while Fig 3B reports the cumulative variance explained by the components. It is obvious that the first principal component explains the absolute majority of the variance while the remaining components explain only a small portion of the variance._

**Table 2. Upper and lower bounds (bootstrapped 95 % confidence intervals) for the proportion of variance explained by principal component 1 to 10**
```{r echo=F, warning=F, message=F, error=F, fig.height=6, fig.width=12}
kable(data.table("bound"=c("Upper bound:", "Lower bound:"), t(round(DT_pca_boot_conf_summary, 3))), col.names=c(" ", paste(rep("PC", 10), 1:10, sep="")), align="c")
```

```{r echo=F, warning=F, message=F, error=F}
#1. Calculation of Barnes-Hut t-Distributed Stochastic Neighbor Embedding
DT_tSNE_raw <- t(DT_lcpm[ENSEMBL_ID %in% gene_variance_top500[, ENSEMBL_ID],-(1:2)])
DT_tSNE <- Rtsne(as.matrix(DT_tSNE_raw), check_duplicates=FALSE, pca=TRUE, perplexity=3, theta=0.5, dims=3)
tSNE_plot_data <- data.table(DT_tSNE$Y, group=DT_meta_data[, group], ID=DT_meta_data[, ID])
```

```{r echo=F, warning=F, message=F, error=F, fig.height=6, fig.width=10}
#1. Creating group name variable
group_names <- c("MSC[in vitro]", "MSC[Naive]", "MSC[SCI]")
#2. Creating color palette for usage in plots downstream
color_palette <- brewer.pal(11, "RdBu")[c(1,2,10)]
#3. Creating ellipse data
#[PCA]
ellipse_data_PCA <- suppressWarnings(do.call(rbind,lapply(split(DT_principal_comp, DT_principal_comp[,group]), function(group.object){data.table(group=group.object[,group], with(group.object, ellipse::ellipse(cor(PC1,PC2), scale = c(sd(PC1), sd(PC2)), centre=c(mean(PC1), mean(PC2)), t=1.5)))})))
#[tSNE]
ellipse_data_tSNE <- suppressWarnings(do.call(rbind,lapply(split(tSNE_plot_data, tSNE_plot_data[,group]), function(group.object){data.table(group=group.object[,group], with(group.object, ellipse::ellipse(cor(V1,V2), scale = c(sd(V1), sd(V2)), centre=c(mean(V1), mean(V2)), t=1.5)))})))
#4. 2D plot [PCA]
PCA_plot <- ggplot(DT_principal_comp, aes(PC1, PC2))+
  geom_segment(aes(x=-100, xend=150, y=0, yend=0), size=0.2)+
  geom_segment(aes(x=0, xend=0, y=-15, yend=20), size=0.2)+
  geom_polygon(ellipse_data_PCA, mapping=aes(x, y, fill=group), alpha=0.2, show.legend=F)+
  geom_point(aes(color=group, shape=group), size=7, alpha=0.8)+

  xlab("PC1")+
  ylab("PC2")+
  
  scale_color_manual(values=brewer.pal(11,"RdBu")[c(1,2,10)], labels=group_names)+
  scale_shape_manual(values=c(18,17,16), labels=group_names)+
  scale_fill_manual(values=brewer.pal(11,"RdBu")[c(1,2,10)], labels=group_names)+
  scale_x_continuous(breaks=seq(-100, 150, 20))+
  scale_y_continuous(breaks=seq(-20, 30, 2))+
  
  theme(legend.title = element_blank(), legend.position = "none", legend.text=element_text(size=20), legend.justification="center", axis.title=element_text(size=22, face="bold"), axis.line=element_blank(), axis.ticks=element_blank())+
  
  annotate("text", x=-15, y=10, label="MSC[Naive]", size=6, fontface=2)+
  annotate("text", x=-15, y=-8, label="MSC[SCI]", size=6, fontface=2)+
  annotate("text", x=120, y=6, label="MSC[in vitro]", size=6, fontface=2)+
  
  annotate(geom="text", x=0, y=0, label="PCA", size=10, fontface=2, alpha=0.7)

#5. 2D plot [tSNE]
tSNE_plot <- function(legend_status){
  plot_out <- ggplot(tSNE_plot_data, aes(V1, V2))+
  geom_segment(aes(x=tSNE_plot_data[, min(V1)]*1.2, xend=tSNE_plot_data[, max(V1)]*1.2, y=0, yend=0), size=0.2)+
  geom_segment(aes(x=0, xend=0, y=tSNE_plot_data[, min(V2)], yend=tSNE_plot_data[, max(V2)]), size=0.2)+
  geom_polygon(ellipse_data_tSNE, mapping=aes(x, y, fill=group), alpha=0.2, show.legend=F)+
  geom_point(aes(color=group, shape=group), size=7, alpha=0.8)+

  xlab("V1")+
  ylab("V2")+
  
  scale_color_manual(values=brewer.pal(11,"RdBu")[c(1,2,10)], labels=group_names)+
  scale_shape_manual(values=c(18,17,16), labels=group_names)+
  scale_fill_manual(values=brewer.pal(11,"RdBu")[c(1,2,10)], labels=group_names)+
  scale_x_continuous(breaks=seq(-100, 150, 20))+
  scale_y_continuous(breaks=seq(-100, 100, 10))+
  
  theme(legend.title=element_blank(), legend.position=legend_status, legend.text=element_text(size=20), legend.justification="center", axis.title=element_text(size=22, face="bold"), axis.line=element_blank(), axis.ticks=element_blank())+
  
  annotate(geom="text", x=0, y=0, label="t-SNE", size=10, fontface=2, alpha=0.7)
  
  return(plot_out)
}

#6. Function: fancy 3D plot
scatter3D_fancy <- function(x, y, z,..., colvar = z, plot_color_palette=color_palette)
  {
   panelfirst <- function(pmat) {
      XY <- trans3D(x, y, z = rep(min(z), length(z)), pmat = pmat)
      scatter2D(XY$x, XY$y, colvar = colvar, pch = ".", 
              cex = 7, add = TRUE, colkey = F, col = plot_color_palette, alpha=0.8)
   
      XY <- trans3D(x = rep(min(x), length(x)), y, z, pmat = pmat)
      scatter2D(XY$x, XY$y, colvar = colvar, pch = ".", 
              cex = 7, add = TRUE, colkey = F, col = plot_color_palette, alpha=0.8)
  }
  scatter3D(x, y, z, ..., colvar = colvar, panel.first=panelfirst,
    colkey = F) 
}

```

**Fig 5. Dimensionality reduction using PCA and t-SNE of the 500 genes with highest variance reporting the first and second leading component/variable**

```{r echo=F, warning=F, message=F, error=F, fig.height=6, fig.width=12}
#Plotting 2D dimension reduction graphs (PCA, tSNE)
PCA_tSNE_legend <- get_legend(tSNE_plot("bottom"))
grid.arrange(arrangeGrob(arrangeGrob(PCA_plot, tSNE_plot("none"), ncol=2), PCA_tSNE_legend, nrow=2, heights=c(6,1)))

```

**Fig 5.** _Fig text_

**Fig 6. Dimensionality reduction using PCA and t-SNE of the 500 genes with highest variance reporting three first components/variables**

```{r echo=F, warning=F, message=F, error=F, fig.height=6, fig.width=10}
par(mfrow=c(1,2), mar=c(4,2,5,1))

#3D plot [PCA] (biological replicates)
scatter3D_fancy(DT_principal_comp$PC1, DT_principal_comp$PC2, DT_principal_comp$PC3, colvar = as.integer(DT_principal_comp$group), 
            pch=19, 
            col = color_palette, 
            alpha=0.7, 
            xlab="PC1",
            ylab="PC2",
            zlab="PC3",
            phi=0,
            main="PCA",
            cex=4, 
            cex.main=3, 
            cex.lab=2)

#3D plot [t-SNE] (biological replicates)
scatter3D_fancy(tSNE_plot_data$V1, tSNE_plot_data$V2, tSNE_plot_data$V3, 
            colvar = as.integer(tSNE_plot_data$group), 
            pch=19, 
            col=color_palette, 
            alpha=0.7, 
            xlab="V1",
            ylab="V2",
            zlab="V3",
            phi=0,
            main="t-SNE",
            cex=4,
            cex.main=3, 
            cex.lab=2)

```

**Fig 6.** _figure text_

**Fig 7. Dimensionality reduction using PCA of the 500 genes with highest variance reporting three first components on 1000 bootstrap replicates of dimensionality reduction**

```{r echo=F, warning=F, message=F, error=F, fig.height=6, fig.width=10}
#1. PCA bootstrap function: bootstrap from top 500 genes with highest variance and calculate PC1, PC2 & PC3 
pca_simulation_function <- function(dataset, run){
  sim_data <- dataset[sample(1:500, replace = T)]
  sim_prcomp_raw <- prcomp(t(sim_data))$x[,(1:3)]
  sim_prcomp <- data.table(ID=rownames(sim_prcomp_raw), sim_prcomp_raw)
  return(sim_prcomp)}
#2. Calling boostrap function, creating data table and merging and adding group name
DT_pca_boot <- do.call(rbind, lapply(1:1000, function(dataset, i){pca_simulation_function(DT_pca_sim, i)}))
DT_pca_boot[, "ID"] <- factor(DT_pca_boot[,ID])
DT_pca_boot <- merge(DT_pca_boot, DT_meta_data[,.(ID, group)], by="ID")

#3D PCA plot [bootstrapped] (with 3D-coordinates)
par(mfrow=c(1,2), mar=c(4,2,5,1))

scatter3D_fancy(DT_pca_boot$PC1, DT_pca_boot$PC2, DT_pca_boot$PC3, 
            colvar=as.integer(DT_pca_boot$group), 
            pch=19, 
            col=color_palette, 
            alpha=0.02, 
            xlab="PC1",
            ylab="PC2",
            zlab="PC3",
            phi=0,
            main="Bootstrap PCA",
            cex=2,
            theta=30,
            cex.main=2.5, 
            cex.lab=2)

#3D PCA plot bootstrapped (without 3D-coordinates)
scatter3D_fancy(DT_pca_boot$PC1, DT_pca_boot$PC2, DT_pca_boot$PC3, 
            colvar=as.integer(DT_pca_boot$group), 
            pch=19, 
            col=color_palette, 
            alpha=0.02, 
            xlab="PC1",
            ylab="PC2",
            zlab="PC3",
            phi=0,
            main="Bootstrap PCA",
            cex=0,
            theta=30,
            cex.main=2.5, 
            cex.lab=2)

```

**Fig 7.** _figure text_

```{r echo=F, warning=F, message=F, error=F}
########################################### UNSUPERVISED LEARNING (all other methods) ############################################
```

**Fig 8. Dimensionality reduction using other common methods of the 500 genes with highest variance reporting the two first components**

```{r echo=F, warning=F, message=F, error=F, fig.height=6, fig.width=12}
#1. Creating data for dimensionality reduction and clustering
dim_data <- DT_lcpm[ENSEMBL_ID %in% gene_variance_top500[,ENSEMBL_ID],-(1:2)]
#2. Function which plots data following dimensionality reduction
dimension_plot_function <- function(data_set, dim_reduction_type, legend.position="none", textboolean=TRUE, cluster_type="none") {
  if(cluster_type!="none"){data_set <- data_set[!is.na(get(cluster_type))]}
  
  dim_plot <- ggplot(data_set, aes(V1, V2))+
    geom_segment(aes(x=data_set[, mean(range(V1))], xend=data_set[, mean(range(V1))], y=data_set[, min(V2)]*1.2, yend=data_set[, max(V2)]), color="black", size=0.1, alpha=0.5)+
    geom_segment(aes(x=data_set[, min(V1)]*1.2, xend=data_set[, max(V1)]*1.2, y=data_set[, mean(range(V2))], yend=data_set[, mean(range(V2))]), color="black", size=0.1, alpha=0.5)+
    
    theme(legend.title=element_blank(), legend.position=legend.position, legend.text=element_text(size=20), legend.justification="center", axis.title=element_blank(), axis.text=element_blank(), axis.line=element_blank(), axis.ticks=element_blank())+
    
    scale_shape_manual(values=c(18,17,16), labels=group_names)+
    
    annotate(geom="text", x=data_set[, mean(range(V1))], y=data_set[, mean(range(V2))], label=dim_reduction_type, size=7, fontface=2, alpha=0.7)
  
    if(cluster_type=="none"){dim_plot <- dim_plot + 
      geom_point(aes(color=group, shape=group), size=7, alpha=0.7)+
      scale_color_manual(values=brewer.pal(11,"RdBu")[c(1,2,10)], labels=group_names)}
  
    if(cluster_type!="none"){dim_plot <- dim_plot + 
      geom_point(aes(color=factor(get(cluster_type)), shape=group), size=10, alpha=0.7)+
      scale_color_manual(values=brewer.pal(11,"RdBu")[c(1,2,10)], labels=c("C1", "C2", "C3"))}
    
    if(textboolean==T){dim_plot <- dim_plot + geom_text(aes(label=ID), show.legend = F, color="black", size=3)}
   
  return(dim_plot)
}

#3. Creating train-rows for algorithms requiring training
train <- sample(1:22, round(22*0.6))

#4. Various types of dimensionality reduction algorithms
#A. SAMMON'S NON-LINEAR MAPPING
invisible(capture.output(sammon_mapping_fit <- sammon(dist(as.matrix(t(dim_data))), k=2, niter=100)))
sammon_mapping_plot_data <- data.table(sammon_mapping_fit$points)
sammon_mapping_plot_data[,`:=`(ID=DT_meta_data[, ID], group=DT_meta_data[,group])]
#B. Classical MDS
MDS_classical_fit <- cmdscale(dist(t(dim_data)), k=2) 
MDS_classical_fit <- data.table(MDS_classical_fit)
MDS_classical_fit[,`:=`(ID=DT_meta_data[, ID], group=DT_meta_data[,group])]
#C. Kruskal's Non-metric MDS
invisible(capture.output(MDS_nonmetric_fit <- isoMDS(dist(t(dim_data)), k=2)))
MDS_nonmetric_fit <- data.table(MDS_nonmetric_fit$points)
MDS_nonmetric_fit[,`:=`(ID=DT_meta_data[, ID], group=DT_meta_data[,group])]
#E. Flexible discriminant analysis
# fda_data <- data.table(t(dim_data), group=DT_meta_data[, factor(group)])
# fda_fit <- fda(group~., data=fda_data[train,])
# predict(fda_fit)
#F. Mixture discriminant analysis (MDA)
# mda_data <- data.table(t(dim_data), group=DT_meta_data[,factor(group)])
# mda_fit  <- mda(group~., subclasses=c(8,6,8),data=mda_data)
# mda_plot_data <- data.table(mda_fit$means[, 1], mda_fit$means[, 2], c("invitro", "naive", "sci"))
# names(mda_plot_data) <- c("V1", "V2", "group")

#G. Singular Value Decomposition (SVD)
svd_data <- data.table(t(dim_data), group=DT_meta_data[, factor(group)])
svd_fit <- svd(svd_data[,1:500])
svd_plot_data <- data.table(V1=svd_fit$u[, 1], V2=svd_fit$u[, 2], group=DT_meta_data[, factor(group)], ID=DT_meta_data[, ID])
#H. Maximum likelihood factor analysis
MLFA_fit <- factanal(dim_data, factors = 2, rotation = "promax")
MLFA_plot_data <- data.table(V1=MLFA_fit$loadings[, 1], V2=MLFA_fit$loadings[, 2], DT_meta_data[, .(group)], DT_meta_data[, .(ID)])
#I. Kernel PCA
kpca_fit <- kpca(t(dim_data), kernel="laplacedot")
kpca_plot_data <- data.table(kpca_fit@pcv[, 1], kpca_fit@pcv[, 2], DT_meta_data[, group], DT_meta_data[, ID])
names(kpca_plot_data) <- c("V1", "V2", "group", "ID")

###SECTION OUTPUT
dimension_legend <- get_legend(dimension_plot_function(kpca_plot_data, "kernel\nPCA", textboolean = F, legend.position = "bottom"))

grid.arrange(arrangeGrob(dimension_plot_function(MDS_classical_fit, "Multidimensional Scaling\n[classical]"),dimension_plot_function(MDS_nonmetric_fit, "Multidimensional scaling\n[nonmetric]"), ncol=2), dimension_legend, nrow=2, heights=c(5,1))

grid.arrange(arrangeGrob(dimension_plot_function(sammon_mapping_plot_data, "Sammon's Non-\nLinear Mapping"), dimension_plot_function(kpca_plot_data, "kernel\nPCA", textboolean = T), ncol=2), dimension_legend, nrow=2, heights=c(5,1))

grid.arrange(arrangeGrob(arrangeGrob(dimension_plot_function(svd_plot_data, "Singular Value\nDecomposition", textboolean = T), dimension_plot_function(MLFA_plot_data, "Maximum Likelihood\nFactor Analysis", textboolean = T), ncol=2), dimension_legend, nrow=2, heights=c(5,1)))

```

***

#Clustering Algorithms

* **Expectation maximisation (EM) using Gaussian Mixture Models (GMM):**
* **Mean-shift:**
* **Spectral clustering:**
* **K-Nearest Neighbour:** Training part consists of storing the class labels of the training samples. Each sample in the test set is then compared to its k-nearest neighbours and assigned the class which is in majority. 
* **Affinity propagation:** Does not require the user to pre-determine the number of clusters. 
* **K-means:** Randomly assign k-number of centroids in the plane. Calculate the distance from each observation to each centroid. Assign the closest centroid/class to each observation. Select the least distant observation from the centroid as the new centroid and repeat the procedure. For precision the algorithm has to be initiated a couple of times since the initial centroid assignment in random.  
* **Support vector machine:**
* **Hierarchical clustering:**

**Fig 9. Hierarchical clustering of samples using 500 most variable genes**

```{r echo=F, warning=F, message=F, error=F, fig.height=5, fig.width=14}
#1. Expectation maximisation (EM) using Gaussian Mixture Models (GMM)
EM_cluster_function <- function(data_set){
  emobj <- simple.init(data_set, nclass=3)
  emobj <- shortemcluster(data_set, emobj)
  model <- emcluster(data_set, emobj, assign.class = TRUE)
  return(model$class)}

EM_PCA  <- EM_cluster_function(DT_principal_comp[, 2:4])
EM_tSNE <- EM_cluster_function(tSNE_plot_data[, 1:3])

#2. Mean-Shift
mean_shift_function <- function(data_set){
  mean_shift_data  <- t(data_set) #Transpose
  mean_shift_data <- mean_shift_data/apply(mean_shift_data, 1, sd) #Normalisation
  candidate_bandwidths <- quantile(dist(t(data_set)), seq(0.01, 0.1, 0.01))
  out <- lapply(candidate_bandwidths, function(band_width){bmsClustering(mean_shift_data, h=band_width)})
  return(out)}

#Not used: does not give more than one cluster (too few replicates) 

#3. Spectral Clustering (SC)
SC_PCA <- specc(as.matrix(DT_principal_comp[, 2:4]), centers=3)@.Data
SC_tSNE <- specc(as.matrix(tSNE_plot_data[, 1:3]), centers=3)@.Data

#4. K-Nearest Neighbour (KNN) (2 neighbours)
knn_function <- function(data_set){
  knn_predict <- class::knn(data_set[train, !"group"], data_set[-train, !"group"], cl=data_set[train, group], k=2)
  data_set[-train, knn:=knn_predict]
  return(data_set[, as.integer(knn)])}

KNN_PCA <- knn_function(DT_principal_comp[, c(1:4, 24)])
KNN_tSNE <- knn_function(tSNE_plot_data)

#5. Affinity Propagation (AP)
affinity_propagation_function <- function(dataset){
  ap_fit <- apcluster(negDistMat(r=2), dataset[, names(dataset)%in%c("PC1", "PC2", "PC3", "V1", "V2", "V3"), with=F])
  names(ap_fit@clusters[[1]]) <- NULL
  cl_1 <- ap_fit@clusters[[1]] ; cl_2 <- ap_fit@clusters[[2]] ; cl_3 <- ap_fit@clusters[[3]]
  out <- rbind(dataset[cl_1][, AP:=1], dataset[cl_2][, AP:=2], dataset[cl_3][, AP:=3])
  return(out)}

AP_PCA <- affinity_propagation_function(DT_principal_comp[, c(1:4, 24)])
AP_tSNE <- affinity_propagation_function(tSNE_plot_data)

#6. K-means Clustering (3 centers, 20 starts)
k_means_PCA <- kmeans(DT_principal_comp[, c(2:4)], centers=3, nstart = 20)$cluster
k_means_tSNE <- kmeans(tSNE_plot_data[, 1:3], centers=3, nstart = 20)$cluster

#7. Support Vector Machine (SVM)
svm_function <- function(dataset, formula){
  svm_fit <- svm(formula, data=dataset[train])
  svm_pred <- predict(svm_fit, dataset[-train])
  out <- dataset[-train, svm:=svm_pred][, as.integer(svm)] 
  return(out)}

SVM_PCA <- svm_function(DT_principal_comp[, c(1:4, 24)], formula(group~PC1+PC2+PC3))
SVM_tSNE <- svm_function(tSNE_plot_data, formula(group~V1+V2+V3))

#Creating cluster datasets
PCA_cluster_data <- cbind(DT_principal_comp[, c(1:4, 24)], EM=EM_PCA, SC=SC_PCA, KM=k_means_PCA, KNN=KNN_PCA, SVM=SVM_PCA)
PCA_cluster_data <- merge(PCA_cluster_data, AP_PCA[, .(ID, AP)], by="ID")

tSNE_cluster_data <- cbind(tSNE_plot_data, EM=EM_PCA, SC=SC_PCA, KM=k_means_tSNE, KNN=KNN_tSNE, SVM=SVM_tSNE)
tSNE_cluster_data <- merge(tSNE_cluster_data, AP_PCA[, .(ID, AP)], by="ID")

#8A. Hierarchical clustering: 500 genes with highest variance

#1. Selecting the 1000 most variable genes (500 to low to separate the remaining two in-vitro samples)
gene_variance_top1000 <- gene_variance[order(-variance)][1:1000]
#1. Creating a dissimilarity structure for the 500 genes with highest variance
setkey(DT_lcpm, ENSEMBL_ID)
DT_dist <- dist(t(DT_lcpm[ENSEMBL_ID %in% gene_variance_top1000[,ENSEMBL_ID],-(1:2)]))
#2. Hierarchical clustering on the dissimilarity structure
DT_hclust <- hclust(DT_dist)

#8B. Circular packing representation

#1. Creating a phylo-object from a hclust-object
DT_hclust_phylo <- as.phylo(DT_hclust)
DT_hclust_edges <- DT_hclust_phylo$edge
#2. Creating data frame and graph data from the data frame
DT_hclust_circularpacking <- data.frame(from=DT_hclust_edges[,1], to=DT_hclust_edges[,2])
DT_hclust_circularpacking <- graph_from_data_frame(DT_hclust_circularpacking)
#3. Create and arrange for addition of group and ID to the data frame
circular_packing_data_adjust  <- function(data_set, n_samples, left_to_right_ID){
  leaf_labels <- data.table(ID=c(rep(NA, length(V(data_set)$name)-n_samples), left_to_right_ID))
  leaf_labels[, "ID"] <- factor(leaf_labels[, ID])
  leaf_labels <- merge(leaf_labels, DT_meta_data[, .(ID, group)], by="ID", sort=F, all=T)
  group_sizes <- data.table(group=c("SCI", "Naive", "invitro"), size=c(1,2,3))
  leaf_labels <- merge(leaf_labels, group_sizes, by="group", sort=F, all=T)

  leaf_labels[,"ID"] <- as.integer(as.character(leaf_labels[,ID]))
  leaf_labels[,"group"] <- as.character(leaf_labels[,group])

  V(data_set)$ID <- leaf_labels$ID
  V(data_set)$group <- leaf_labels$group
  return(data_set)
}
#4. Adjusting data frame prior to plotting (adding leaf numbers manually from dendrogram) 
DT_hclust_circularpacking <- circular_packing_data_adjust(DT_hclust_circularpacking, 22, c(132, 134, 136, 135, 129, 130, 131, 133, 104, 102, 105, 107, 127, 106, 108, 101, 103, 122, 123, 124, 125, 126))
#5. Creating the circular packing plot
color_palette_RdBu <- brewer.pal(11, "RdBu")[c(1:4, 9:11)]

hierarchical_clustering_circular_1000 <- ggraph(DT_hclust_circularpacking, layout='circlepack')+
  geom_node_circle(aes(fill = as.factor(depth), color = as.factor(depth)), alpha=0.6)+
  scale_fill_manual(values=c("0"="white", "1"="white", "2"=color_palette_RdBu[2], "3"=color_palette_RdBu[3], "4"=color_palette_RdBu[4], "5"=color_palette_RdBu[5], "6"=color_palette_RdBu[6], "7"=color_palette_RdBu[7]))+
  scale_color_manual(values=c("0" = "white", "1" = "white", "2" = color_palette_RdBu[2], "3" = color_palette_RdBu[3], "4"=color_palette_RdBu[4], "5"=color_palette_RdBu[5], "6"=color_palette_RdBu[6], "7"=color_palette_RdBu[7]))+
  
  theme_void()+
  theme(legend.position="FALSE")+
  geom_node_text(aes(label=group, filter=leaf), size=2.5, fontface=2)

### SECTION OUTPUT
par(mfrow=c(1,2))

grid.arrange(arrangeGrob(
  
grob(myplclust(DT_hclust, labels=paste(DT_meta_data[,group]," ","(", DT_meta_data[,ID],")", sep=""), main="", ylab="", lab.col=brewer.pal(11, "RdBu")[c(1,2,10)][as.numeric(DT_meta_data[,group])], font=2, cex=1, hang=0.05)),

hierarchical_clustering_circular_1000, ncol=2))

```

**Fig 9.** _Figure reports hierarchical clustering based on te 500 most variable genes. Left figure reports the clustering using a dendrogram while the right figure reports the same clustering using a circular packing plot._

**Fig 10. Clustering of samples using common methods following dimensionality reduction with PCA and tSNE.**

```{r echo=F, warning=F, message=F, error=F, fig.width=12, fig.height=6}
#Aligning column names
setnames(PCA_cluster_data, c("PC1", "PC2", "PC3"), c("V1", "V2", "V3"))

### SECTION OUTPUT [2D plots]
cluster_legend <- get_legend(dimension_plot_function(PCA_cluster_data, "Expectation Maximum\n[PCA]", cluster_type = "EM", legend.position = "bottom"))

#Expectation Maximum
grid.arrange(arrangeGrob(arrangeGrob(dimension_plot_function(PCA_cluster_data, "Expectation Maximum\n[PCA]", cluster_type = "EM"), dimension_plot_function(tSNE_cluster_data, "Expectation Maximum\n[tSNE]", cluster_type = "EM"), ncol=2), cluster_legend, nrow=2, heights=c(5,1)))
#Spectral Clustering
grid.arrange(arrangeGrob(arrangeGrob(dimension_plot_function(PCA_cluster_data, "Spectral Clustering (3Cs)\n[PCA]", cluster_type = "SC"), dimension_plot_function(tSNE_cluster_data, "Spectral Clustering(3Cs)\n[tSNE]", cluster_type = "SC"), ncol=2), cluster_legend, nrow=2, heights=c(5,1)))
#K-Means Clustering
grid.arrange(arrangeGrob(arrangeGrob(dimension_plot_function(PCA_cluster_data, "K-Means Clustering (3Cs)\n[PCA]", cluster_type = "KM"), dimension_plot_function(tSNE_cluster_data, "K-Means Clustering (3Cs)\n[tSNE]", cluster_type = "KM"), ncol=2), cluster_legend, nrow=2, heights=c(5,1)))
#K-Nearest Neighbour
grid.arrange(arrangeGrob(arrangeGrob(dimension_plot_function(PCA_cluster_data, "K-Nearest Neighbour (train:test-60:40)\n[PCA]", cluster_type = "KNN"), dimension_plot_function(tSNE_cluster_data, "K-Nearest Neighbour (train:test-60:40)\n[tSNE]", cluster_type = "KNN"), ncol=2), cluster_legend, nrow=2, heights=c(5,1)))
#Support Vector Machine
grid.arrange(arrangeGrob(arrangeGrob(dimension_plot_function(PCA_cluster_data, "Support Vector Machine (train:test-60:40)\n[PCA]", cluster_type = "SVM"), dimension_plot_function(tSNE_cluster_data, "Support Vector Machine (train:test-60:40)\n[tSNE]", cluster_type = "SVM"), ncol=2), cluster_legend, nrow=2, heights=c(5,1)))
#Affinity Propagation
grid.arrange(arrangeGrob(arrangeGrob(dimension_plot_function(PCA_cluster_data, "Affinity Propagation\n[PCA]", cluster_type = "AP"), dimension_plot_function(tSNE_cluster_data, "Affinity Propagation\n[tSNE]", cluster_type = "AP"), ncol=2), cluster_legend, nrow=2, heights=c(5,1)))


```

**Fig 10.** _Figure reports result of common clustering algorithms implemented on samples following dimensionality reduction using PCA and tSNE. In the case train-test split was required a 60:40 ratio (13:9 samples) was used instead of a traditional 80:20 ratio due to low number of samples in the test set._

**Fig 11. Clustering of 200 random bootstrap replicates for each sample using affinity propagation and k-means clustering** 

```{r echo=F, warning=F, message=F, error=F, fig.width=12, fig.height=6}
#3D illustration of clustering (AP, K-means) on bootstrapped PCA-data
#Sample 200 from each ID
DT_pca_boot_sample <- do.call(rbind, lapply(split(DT_pca_boot, DT_pca_boot[, .(ID)]), function(subset){subset[sample(.N, 200, replace=F)]}))
#Shuffle the rows to get a better clustering
DT_pca_boot_sample <- DT_pca_boot_sample[sample(.N, .N)]

#A. Affinity Propagation
AP_PCA_boot <- affinity_propagation_function(DT_pca_boot_sample)
#B. K-Means Clustering
KM_PCA_boot <- kmeans(DT_pca_boot_sample[,c(2:4)], centers=3, nstart=20)
KM_PCA_boot <- data.table(DT_pca_boot_sample[,c(2:4)], KM=KM_PCA_boot$cluster)

###SECTION OUTPUT
par(mfrow=c(1,2), mar=c(4,2,5,1))

scatter3D_fancy(AP_PCA_boot$PC1, AP_PCA_boot$PC2, AP_PCA_boot$PC3, colvar = as.integer(AP_PCA_boot$AP), plot_color_palette=color_palette[c(2,1,3)], 
            pch=19, 
            col=color_palette[c(2,1,3)], 
            alpha=0.7, 
            xlab="PC1",
            ylab="PC2",
            zlab="PC3",
            phi=0,
            main="Bootstrap PCA\n[Affinity Propagation]",
            cex=2,
            cex.main=2.5, 
            cex.lab=2)

scatter3D_fancy(KM_PCA_boot$PC1, KM_PCA_boot$PC2, KM_PCA_boot$PC3, colvar = as.integer(KM_PCA_boot$KM), plot_color_palette=color_palette[c(1,3,2)], 
            pch=19, 
            col=color_palette[c(1,3,2)], 
            alpha=0.7, 
            xlab="PC1",
            ylab="PC2",
            zlab="PC3",
            phi=0,
            main="Bootstrap PCA\n[K-means]",
            cex=1,
            cex.main=2.5, 
            cex.lab=2)

```

**Fig 11.** _Figure reports 3-dimensional representations of clustering using affinity propagation and k-means clustering of 200 random bootstrap replicates of PCA per sample._

***

**Fig 12. Top ten loadings (absolute value) for the first four principal components**

```{r echo=F, warning=F, message=F, error=F, fig.height=6, fig.width=12}
#1. Selecting PC1 and PC2 and adding gene names 
DT_loadings <- data.table(SYMBOL=gene_variance_top500[,SYMBOL], DT_principal_comp_raw$rotation[,(1:2)])
#2. Creating table data
DT_loadings_sub_function <- function(data.load, pc.type, n){
  load_out <- data.load[,.(SYMBOL, get(pc.type))][order(V2)]
  load_out <- rbind(tail(load_out, n), head(load_out, n))
  load_out[,"V2"] <- round(load_out[, V2],3)
  load_out <- load_out[ ,PC.type:=pc.type]
  names(load_out) <- c("Gene", "PC.value", "PC.type")
  return(load_out)  
}

DT_loadings_plotdata <- rbind(DT_loadings_sub_function(DT_loadings[!is.na(SYMBOL)],"PC1", 10), DT_loadings_sub_function(DT_loadings[!is.na(SYMBOL)],"PC2", 10))

#3. Adding a type variable for plotting purposes
DT_loadings_plotdata <- DT_loadings_plotdata[,sign.type:=factor(ifelse(PC.value>0,"pos","neg"))]
#4. Plotting function [traditional barplot]
DT_loadings_plot_function <- function(data.set.loading, pc.type){
  data.set.loading <- data.set.loading[PC.type==pc.type]
  data.set.loading[,"Gene"] <- factor(data.set.loading[, Gene], levels=unique(data.set.loading[,Gene]))
  
  DT_loadings_out <- ggplot(data.set.loading, aes(Gene, PC.value, fill=PC.type))+
  geom_bar(aes(alpha=sign.type), stat="identity", show.legend = F)+
  geom_text(data.set.loading[PC.value>0], mapping=aes(label=round(PC.value,2)), hjust=-0.5, fontface=2, size=5)+
  geom_text(data.set.loading[PC.value<0], mapping=aes(label=round(PC.value,2)), hjust=1.5, fontface=2, size=5)+
  geom_segment(aes(x=0, xend=20, y=0, yend=0), size=2, linetype=2)+
  coord_flip()+
  
  scale_y_continuous(breaks=seq(-0.5, 0.5, 0.05), limits=c(-0.3, 0.3))+
  scale_alpha_manual(values=c(0.7,0.9))+
  
  theme(axis.text.x = element_text(size=12), axis.title.x = element_text(face="bold", size=22), axis.title.y = element_blank(), axis.text.y = element_text(size=15))
  
  if(pc.type=="PC1"){
    DT_loadings_out <- DT_loadings_out+scale_fill_manual(values=brewer.pal(11, "RdBu")[1])+annotate("text", x=20, y=-0.25, label="A", size=7.5, fontface=2) + ylab("Principal component 1")
  } else if(pc.type=="PC2"){
    DT_loadings_out <- DT_loadings_out+scale_fill_manual(values=brewer.pal(11, "RdBu")[11])+annotate("text", x=20, y=-0.25, label="B", size=7.5, fontface=2)+ylab("Principal component 2")
  }
  
  return(DT_loadings_out)
}

#5. Plotting loadingsdata [Circular barplot]
#A. Selecting 500 most variable genes
loadings_data_circular <- data.table(SYMBOL=gene_variance_top500[,SYMBOL], DT_principal_comp_raw$rotation[,(1:4)])
#B. Converting PC-value to absolute values
loadings_data_circular[,2:5] <- loadings_data_circular[, lapply(.SD, function(column){abs(column)}), .SDcols=names(loadings_data_circular)[2:5]]
#C. Sorting each principal component separately
loadings_data_circular_melt <- do.call(rbind, lapply(c(names(loadings_data_circular)[2:5]), function(column){loadings_data_circular[, .(SYMBOL, get(column))][order(-V2)][,PC:=substr(column, 3, 3)][1:10]}))
names(loadings_data_circular_melt) <- c("SYMBOL", "value", "PC")
#D. Converting PC to a factor variable
loadings_data_circular_melt[, "PC"] <- factor(loadings_data_circular_melt[, PC])
#E. Arranging data for plotting
empty_bar <- 3
to_add <- data.table(matrix(NA, empty_bar*nlevels(loadings_data_circular_melt$PC), ncol(loadings_data_circular_melt)))
names(to_add) <- colnames(loadings_data_circular_melt)
to_add$PC <- rep(levels(loadings_data_circular_melt$PC), each=empty_bar)
loadings_data_circular_melt <- rbind(loadings_data_circular_melt, to_add)
loadings_data_circular_melt <- loadings_data_circular_melt[order(PC)]
loadings_data_circular_melt$id=seq(1, nrow(loadings_data_circular_melt))
#F. Adjusting values for easier plotting
loadings_data_circular_melt[, value:=value*100]
#G. Get the name and the y position of each label
label_data <- loadings_data_circular_melt
number_of_bar <- nrow(label_data)
angle <- 90 - 360 * (label_data$id-0.5) /number_of_bar 
label_data$hjust<-ifelse(angle < -90, 1, 0)
label_data$angle<-ifelse(angle < -90, angle+180, angle)
#H. Prepare a data frame for base lines
base_data <- loadings_data_circular_melt[, .(start=min(id), end=max(id)-empty_bar), by="PC"]
base_data[, title:=apply(base_data[, 2:3], 1, mean)]
#I. Creating the plot
circular_loadings_plot <-  ggplot(loadings_data_circular_melt, aes(x=as.factor(id), y=value, fill=PC))+
  geom_bar(aes(x=as.factor(id), y=value, fill=PC), stat="identity", alpha=0.5)+
  annotate("text", x = rep(max(loadings_data_circular_melt$id), 4), y = seq(0, 12, 4), label = c("0", "0.1", "0.2", "0.3") , color="grey", size=3, angle=0, fontface="bold", hjust=1)+

  ylim(-10, 30)+
  theme_minimal()+
  theme(legend.position = "none", axis.text = element_blank(), axis.title = element_blank(), panel.grid = element_blank(), plot.margin = unit(c(-2, -1, 0, 0), "cm"))+
  coord_polar()+
  
  geom_text(data=label_data, aes(x=id, y=value*1.05, label=SYMBOL, hjust=hjust), color="black", fontface="bold",alpha=0.6, size=2.5, angle= label_data$angle, inherit.aes = FALSE)+
  geom_segment(data=base_data, aes(x = start, y = -1, xend = end, yend = -1), colour = "black", alpha=0.8, size=0.6, inherit.aes = FALSE)+
  geom_text(data=base_data, aes(x = title, y = -3, label=PC), hjust=c(1,1,0,0), colour = "black", alpha=0.8, size=4, fontface="bold", inherit.aes = FALSE)+
  
  annotate(geom="text", x=0, y=-9, label="PC", fontface=2)+
  
  scale_fill_manual(values=color_palette_RdBu[c(1,2,6,7)])

###SECTION OUTPUT
circular_loadings_plot
```

**Fig 12.** _Figure reports the top ten loadings (genes) using absolute values for the first four principal components._

**Fig 13. Top 10 positive and negative loadings for the first -and second principal component**

```{r echo=F, warning=F, message=F, error=F, fig.height=5, fig.width=14}
grid.arrange(DT_loadings_plot_function(DT_loadings_plotdata, "PC1"), DT_loadings_plot_function(DT_loadings_plotdata,"PC2"), ncol=2, left=textGrob("Gene", gp=gpar(fontface="bold", fontsize=17), rot=90))
```

**Fig 13.** _Figure reports the top 10 positive and negative loadings for the first -and second principal component._

***

#Negative Binominal Dispersions by Weighted Likelihood Empirical Bayes  

**Fig 14. Cox-Reid profile-adjusted likelihood estimated tagwise, common and trended dispersions**

```{r echo=F, warning=F, message=F, error=F, fig.width=12, fig.height=5} 
#1. Setting up a design matrix (a dummy matrix indicating which group each sample belongs to)
DT_design <- model.matrix(~0+DT_meta_data[,group])
colnames(DT_design) <- c("MSCsci", "MSCnaive", "MSCinvitro")

#2. Estimating dispersions (common, trended and tagwise)
DT_dispersion <- estimateDisp(DGEList(DT_read_count_filtered[,-(1:2)], lib.size = DT_meta_data[,effective.library.size]), design = DT_design, trend.method = "loess")

DT_dispersion_tagwise <- data.table(DT_dispersion$AveLogCPM, DT_dispersion$tagwise.dispersion)
names(DT_dispersion_tagwise) <- c("average.logCPM", "tagwise")

#3. Plotting dispersions
plot_dispersion <- ggplot(DT_dispersion_tagwise, aes(average.logCPM, tagwise))+
  geom_point(alpha=0.3)+
  geom_smooth(color="dodgerblue2", se=F, span=2, method="loess", size=1.2)+
  geom_segment(aes(x=-1.25, xend=14.5, y=DT_dispersion$common.dispersion, yend=DT_dispersion$common.dispersion), color="red", size=1.25)+

  xlab("Average log-CPM")+
  ylab("Biological coefficient of variation (BCV)")+
  
  scale_y_continuous(limits=c(-0.1,1), breaks=seq(-0.1,1,0.1))+
  scale_x_continuous(breaks=seq(-10,15,1))+
  
  annotate("text", x=12.5, y=0.9, label="Common", fontface=2, color="red")+
  annotate("text", x=12.5, y=0.85, label="Trended", fontface=2, color="dodgerblue2")+
  annotate("text", x=12.5, y=0.8, label="Tagwise", fontface=2, color="black")+
  
  theme(axis.title.x = element_text(face="bold", size=17), axis.title.y = element_text(face="bold", size=14))
  
####SECION OUTPUT
plot_dispersion

```

**Fig 14. ** _Figure reports tagwise, common and trended dispersions._

***

```{r echo=F, warning=F, message=F, error=F}
########################################### Removing heteroscedasticity ############################################
```

# Linear Modelling and Empirical Bayes Moderation Using Precision Weights 

**Background:** The variance of raw counts is not independent of its mean. Furthermore, the variance of raw counts increases with the count size (opposite is true for log-counts). 

**Voom transformation:** Acronym for mean-variance modelling at the observational level. The mean-variance relationship is estimated in the data which is then used for computing precision weights for each gene. The precision weights are then implemented in the linear modelling in order to adjust for heteroscedasticity. Estimation of precision weights is done as follows: 1) log-CPM=log2(raw count + 0.5), 2) a linear modelled is fitted to each gene, 3) lowess function is fitted to the scatterplot between average log-CPM and sqrt(st.dev), 4) the variance of the log-CPM for each gene is predicted using the lowess trend line 5) the inverse of the variance for each log-CPM value is the precision weight.     

**Empirical Bayes moderation of standard error:** Ranks genes in order of evidence of differential expression. 

**Fig 10. Mean-variance relationship pre -and post voom transformation**

```{r echo=F, warning=F, message=F, error=F, fig.height=4, fig.width=12}
#1. Setting up a contrast matrix for pairwise comparisons
DT_contrast <- makeContrasts(
  MSCsci_MSCnaive = MSCsci-MSCnaive,
  MSCsci_MSCinvitro = MSCsci-MSCinvitro,
  MSCnaive_MSCinvitro = MSCnaive-MSCinvitro,
  levels = colnames(DT_design)
)

#2. Applying voom (precision weights modelling of mean-variance relationship)
DT_voom_raw <- voom(DT_read_count_filtered[,-(1:2)], lib.size = DT_meta_data[,effective.library.size], save.plot = T)

#3. Fit a linear model for each gene
DT_vfit <- lmFit(DT_voom_raw$E, design = DT_design, weights = DT_voom_raw$weights)

#4. Calculate coefficients and standard errors for each linear model (i.e. gene)
DT_vfit <- contrasts.fit(DT_vfit, contrasts = DT_contrast)

#5. Calculate moderated F & t-statistics, log odds of differential expression using emiprical Bayes moderation for each linear model (i.e. gene)
DT_efit <- eBayes(DT_vfit)

#6. Creating a DT_efit object using limma-trend instead of voom trend
DT_vfit_limmaTrend <- lmFit(DT_lcpm[,-(1:2)], design=DT_design)
DT_vfit_limmaTrend <- contrasts.fit(DT_vfit_limmaTrend, contrasts = DT_contrast)
DT_efit_limmaTrend <- eBayes(DT_vfit_limmaTrend)

#7. Plotting mean-variance plot for voom
DT_voom_plotdata <- data.table(log.cpm=DT_voom_raw$voom.xy$x,quarter.var=DT_voom_raw$voom.xy$y)
DT_efit_plotdata <- data.table(Amean=DT_efit$Amean, log2.sigma=log2(DT_efit$sigma))

voom_plot <- ggplot(DT_voom_plotdata, aes(log.cpm, quarter.var))+
  geom_point(alpha=0.3)+
  geom_smooth(method="loess", color="red", se=F, linetype=2, size=1.5)+
  
    ylab("Sqrt (St.Dev)")+
  
  scale_x_continuous(breaks=seq(0,18,2))+
  scale_y_continuous(breaks=seq(0,3,0.5), limits=c(0.25,2.5))+

  theme(axis.title.y = element_text(face="bold", size=17), axis.title.x = element_blank())+
  annotate("text", x=0, y=2.5, label="A", size=7.5, fontface=2)

bayes_plot <- ggplot(DT_efit_plotdata, aes(Amean, log2.sigma))+
  geom_point(alpha=0.3)+
  geom_smooth(method="loess", color="red", se=F, linetype=2, size=1.5, span=1.25)+
  geom_segment(aes(x=-3.5, xend=14.5, y=mean(DT_efit_plotdata[,log2.sigma], na.rm=T), yend=mean(DT_efit_plotdata[,log2.sigma], na.rm=T)), color="dodgerblue2", size=1.5, alpha=0.5)+
  
  ylab("log2 (St.Dev)")+
  
  scale_x_continuous(breaks=seq(-2,14,2))+
  scale_y_continuous(breaks=seq(-4,4,0.5), limits=c(-2.5,2.5))+

  theme(axis.title.y = element_text(face="bold", size=17), axis.title.x = element_blank())+
  annotate("text", x=-3.5, y=2.5, label="B", size=7.5, fontface=2)

###SECTION OUTPUT
grid.arrange(voom_plot, bayes_plot, ncol=2, nrow=1, bottom=textGrob("Average log-CPM", gp=gpar(fontsize=17, fontface="bold")))
```

**Fig 10.** _Figure reports the mean-variance relationship pre -and post application of the voom function. Fig 9A reports the average log-CPM against the quarter root of the variance. Fig 9B reports average log-CPM against the log2(st.dev). Blue line reports the average log2(st.dev). The red line is a linear trend fitted to the black dots. Each black dot represents a gene. Fig 9A illustrates that the variance is decresing when the average expression is increasing. In Fig 9B the dependency is removed and the mean variance is unchanged when the average expression increases._      

```{r echo=F, warning=F, message=F, error=F, fig.width=14, fig.height=5}
#Hierarchical clustering of the 1000 genes with highest F-value
#1. Calculating F-statistica
DT_toptableF <- data.table(topTableF(DT_efit, number=Inf, genelist = DT_read_count_filtered[,SYMBOL]))
#2. Subsetting the 500 genes with the highest F-statistica
DT_toptableF <- DT_toptableF[!is.na(ProbeID)][1:1100, ProbeID]
#3. Retrieving log-CPM values for the genes
DT_toptableF <- DT_lcpm[DT_lcpm[,SYMBOL] %in% DT_toptableF]
#4. Creating a dissimilarity matrix
DT_toptableF <- dist(t(DT_toptableF[,-(1:2)]))
#5. Hierarchical clustering  
DT_toptableF <- hclust(DT_toptableF)
#6. Creating dataset for circular packing plot
DT_toptableF_phylo <- as.phylo(DT_toptableF)
DT_toptableF_edges <- DT_toptableF_phylo$edge
#7. Creating data frame and graph data from the data frame
DT_toptableF_circularpacking <- data.frame(from=DT_toptableF_edges[,1], to=DT_toptableF_edges[,2])
DT_toptableF_circularpacking <- graph_from_data_frame(DT_toptableF_circularpacking)
#8. Adding ID and group identities to data frame 
DT_toptableF_circularpacking <- circular_packing_data_adjust(DT_toptableF_circularpacking, 22, c(133, 131, 129, 134, 135, 132, 130, 136, 122, 101, 103, 126, 123, 124, 125, 127, 108, 102, 104, 106, 105, 107))
#9. Creating the circular packing plot
hierarchical_clustering_circular_Fstatistica <- ggraph(DT_toptableF_circularpacking, layout='circlepack')+
  geom_node_circle(aes(fill = as.factor(depth), color = as.factor(depth)), alpha=0.6)+
  scale_fill_manual(values=c("0"="white", "1"="white", "2"=color_palette_RdBu[2], "3"=color_palette_RdBu[3], "4"=color_palette_RdBu[4], "5"=color_palette_RdBu[5], "6"=color_palette_RdBu[6], "7"=color_palette_RdBu[7], "8"=color_palette_RdBu[8]))+
  scale_color_manual(values=c("0" = "white", "1" = "white", "2" = color_palette_RdBu[2], "3" = color_palette_RdBu[3], "4"=color_palette_RdBu[4], "5"=color_palette_RdBu[5], "6"=color_palette_RdBu[6], "7"=color_palette_RdBu[7], "8"=color_palette_RdBu[8]))+
  
  theme_void()+
  theme(legend.position="FALSE")+
  geom_node_text(aes(label=group, filter=leaf), size=2, fontface=2)

###SECTION OUTPUT
par(mfrow=c(1,2))

grid.arrange(arrangeGrob(
  
grob(myplclust(DT_toptableF, labels = paste(DT_meta_data[,group]," ","(", DT_meta_data[,ID], ")", sep=""), lab.col = brewer.pal(11,"RdBu")[c(1,2,10,11)][as.numeric(DT_meta_data[,group])], main=" ", ylab=" ", font=2, cex=1, hang=0.05)),

hierarchical_clustering_circular_Fstatistica, ncol=2))

```

***

# Differential Gene Expression
**Determining significant gene differential expression for a contrast:** A simple Bayesian model is used for moderating standard errors across genes (squeeze them towards a common value) and producing moderated t-statistics. These moderated t-statistics are used for significance analysis. Moderated t-statistics have a higher degree of freedom in comparison to usual t-statistics due to the increase in reliability resulting from the smoothening of standard errors. P-values are adjusted for multiple testing using Benjamini and Hochberg's method to control for false discovery rate (FDR). 

**Fig 11. Number of differentially expressed genes for each contrast**

```{r echo=F, warning=F, message=F, error=F, fig.show='hide'}
#1. Summarizing the number of up - and downregulated differentially expressed genes
DT_dge <- decideTests(DT_efit, adjust.method = "BH")
#2. Converting DT_dge into logical (-1 and 1 is TRUE and 0 is FALSE) 
venn_data_logical <- do.call(cbind, lapply(data.table(DT_dge), function(column){column!=0}))
#3. Function for retrieving data to add to venndiagram
venn_data_function <- function(data.set, c1=NULL, c2=NULL, c3=NULL){
  out <- sum(rowSums(data.set[,c(c1, c2, c3)]) %in% length(c(c1, c2, c3)))
  return(out)
}
#4. Venn diagram: injured only 
venn_plot <- invisible(draw.triple.venn(sum(venn_data_logical[,1]), 
               sum(venn_data_logical[,2]), 
               sum(venn_data_logical[,3]), 
               venn_data_function(venn_data_logical,1,2),
               venn_data_function(venn_data_logical,2,3),
               venn_data_function(venn_data_logical,1,3),
               venn_data_function(venn_data_logical,1,2,3),
               category=c("MSC[SCI] - MSC[Naive]", "MSC[SCI] - MSC[in vitro]", "MSC[Naive] - MSC[in vitro]"),
               lwd=c(2,2,2),
               fill=brewer.pal(11,"RdBu")[c(2,4,9)],
               alpha=0.7,
               cex=2,
               cat.cex=1.5,
               cat.col= brewer.pal(11,"RdBu")[c(2,4,9)],
               cat.fontface=2,
               cat.just=list(c(0.6, -6), c(0.5,-6), c(0.5, 6)),
               cat.default.pos = "text",
               margin=c(0.2)))

```

```{r echo=F, warning=F, message=F, error=F, fig.width=6, fig.height=6, fig.align='center'}
###SECTION OUTPUT
grid.arrange(arrangeGrob(gTree(children=venn_plot)))
```

**Fig 11.** _Figure reports venn diagrams containing the number of differentially expressed genes for each contrast._

**Table 3. Number of differentially over -and under-expressed genes for each contrast**

```{r echo=F, warning=F, message=F, error=F, fig.width=15, fig.height=6, fig.align='center'}
#Summary table
DT_dge_summary <- as.data.frame.matrix(summary(DT_dge))
DT_dge_summary <- rbind(DT_dge_summary, colSums(DT_dge_summary))
rownames(DT_dge_summary) <- c("Downregulated:", "No change", "Upregulated:", "Sum:")
kable(DT_dge_summary, col.names = c("MSC[SCI]-MSC[naive]", "MSC[SCI]-MSC[invitro]", "MSC[naive]-MSC[invitro]"), align="c")

```

**Fig 12. Mean difference -and volcano plot**

```{r echo=F, warning=F, message=F, error=F, fig.width=14, fig.height=5}
#1. Creating plotting data for mean-difference plot
DT_mean_difference <- data.table(toptable(DT_efit, coef=1, number=Inf, genelist = DT_read_count_filtered[,SYMBOL], A=DT_efit$Amean))
DT_mean_difference <- DT_mean_difference[!is.na(ID)]

#2. Plotting mean-difference
mean_difference_plot <- ggplot(DT_mean_difference, aes(AveExpr,logFC))+
  geom_jitter(DT_mean_difference[(logFC>(-1) & logFC<1)], mapping=aes(AveExpr, logFC), alpha=0.7, size=3)+
  geom_jitter(DT_mean_difference[(logFC<=(-1) | logFC>=1) & adj.P.Val>1e-6], mapping=aes(AveExpr, logFC), color="dodgerblue4", alpha=0.8, size=3)+
  geom_jitter(DT_mean_difference[(logFC<=(-1) | logFC>=1) & adj.P.Val<1e-6], mapping=aes(AveExpr, logFC), color="red", alpha=0.5, size=3)+
  geom_segment(aes(x=-5, xend=15, y=-1,yend=-1), size=1.5, color="dodgerblue2", linetype=2)+
  geom_segment(aes(x=-5, xend=15, y=1,yend=1), size=1.5, color="dodgerblue2", linetype=2)+
  
  annotate("text", x=12, y=5.5, label=nrow(DT_mean_difference[logFC>=1 & adj.P.Val>0.05]), color="dodgerblue4", fontface=2, alpha=0.8, size=4.5)+
    annotate("text", x=12, y=-5.5, label=(nrow(DT_mean_difference[logFC<=-1 & adj.P.Val>0.05])+2), color="dodgerblue4", fontface=2, alpha=0.8, size=4.5)+

  annotate("text", x=12, y=-3.5, label=(nrow(DT_mean_difference[logFC<=-1 & adj.P.Val<0.05])+2), color="red", fontface=2, alpha=0.8, size=4.5)+
  annotate("text", x=12, y=3.5, label=nrow(DT_mean_difference[logFC>=1 & adj.P.Val<0.05]), color="red", fontface=2, alpha=0.8, size=4.5)+

  annotate("text", x=12, y=2, label=nrow(DT_mean_difference[logFC>=1]), color="grey", fontface=2, size=4.5)+
  annotate("text", x=12, y=-2, label=(nrow(DT_mean_difference[logFC<=-1])+4), color="grey", fontface=2, size=4.5)+
  
  scale_x_continuous(breaks=seq(-5,15,1))+
  scale_y_continuous(breaks=seq(-20,10,2))+
  
  xlab("Average log-CPM")+
  ylab("Log2(fold change)")+
  
  annotate("text", x=11, y=8, label="UP-REGULATED", fontface=2, alpha=0.6, size=5)+
  annotate("text", x=11, y=-8, label="DOWN-REGULATED", fontface=2, alpha=0.6, size=5)+
  annotate("text", x=-5, y=10, label="A", fontface=2, size=7.5)+
  
  theme(axis.title = element_text(face="bold", size=22))

#Volcano plot
#1. Extracting log odds (i.e. -log10(p.value))
volcano_temp <- data.table(DT_read_count_filtered[,SYMBOL], DT_efit$lods[,1])
names(volcano_temp) <- c("ID","log.odds")
volcano_temp <- volcano_temp[!is.na(ID)]

#2. Merging log odds with logFc and adj.P.val data for plotting
DT_volcano <- merge(DT_mean_difference, volcano_temp, by="ID")

#3. Plotting function for volcano plot
volcano_plot <- ggplot(DT_volcano,aes(logFC,log.odds))+
  geom_jitter(DT_volcano[log.odds<1 & (logFC>=1 | logFC<=(-1))], mapping=aes(logFC, log.odds), alpha=0.7, size=3, color="dodgerblue4")+
  geom_jitter(DT_volcano[!(logFC>=1 | logFC<=(-1))], mapping=aes(logFC, log.odds), alpha=0.7, size=3)+
  geom_jitter(DT_volcano[log.odds>1 & (logFC>=1 | logFC<=(-1))], mapping=aes(logFC, log.odds), color="red", alpha=0.5, size=3)+
  
  geom_segment(aes(x=-1, xend=-1, y=-8,yend=8), size=1.5, color="dodgerblue2", linetype=2)+
  geom_segment(aes(x=1, xend=1, y=-8,yend=8), size=1.5, color="dodgerblue2", linetype=2)+
  geom_segment(aes(x=-7, xend=6, y=1, yend=1), size=0.5, color="dodgerblue2")+
  
  scale_y_continuous(breaks=seq(-10,50,5))+
  scale_x_continuous(breaks=seq(-7,6,1), limits=c(-7,6))+
  
  ylab("-log10(p.value)")+
  xlab("Log2(fold change)")+
  
  annotate("text", x=4, y=50, label="UP-REGULATION", fontface=2, alpha=0.6, size=5)+
  annotate("text", x=-4, y=50, label="DOWN-REGULATION", fontface=2, alpha=0.6, size=5)+
  annotate("text", x=-7, y=50, label="B", fontface=2, size=7.5)+
  
  theme(axis.title = element_text(face="bold", size=22))

###SECTION OUTPUT
plot_grid(mean_difference_plot, volcano_plot)

# ggsave("mean_difference_plot.jpg",mean_difference_plot, dpi=1000, height=7, width=14)
# ggsave("volcano_plot.jpg",volcano_plot, dpi=1000, height=7, width=14)

```

**Fig 12.** _Figure 11A reports a mean-difference plot which illustrates the number of over -and under expressed genes. Threshold is set at log2(fold change) +/-1 (blue lines). Blue dots represents genes above or below the log-fold change thresholds while red dots represent those genes which are above/below the thresholds and are significantly (p<1e-6) differentially expressed. Fig 11B is a volcano plot which reports the number of significantly (p<1e-6) over -and underexpressed genes (marked with red). Blue dots represent genes which have logFC <-1 or >1 but are not significantly expressed. Data in both plots is for the contrast "MSC[SCI] vs MSC[naive]"._

**Table 4. 10 most significantly up -and downregulated differentially expressed genes**

```{r echo=F, warning=F, message=F, error=F}
#1. Function for retrieving logFC and associated p-values for most over -and underexpressed genes 
top_20_dge_retreiver <- function(dge.data, n, p.val.cutoff){
  top_20_dge_out <- data.table(toptable(dge.data, coef=1, number=Inf, genelist = DT_read_count_filtered[,ifelse(is.na(SYMBOL), ENSEMBL_ID, SYMBOL)]))
  top_20_dge_out <- top_20_dge_out[,.(ID, logFC=round(logFC, 2), adj.P.Val=format(adj.P.Val, scientific=T, digits=2))]
  top_20_dge_out <- data.table(top_20_dge_out[logFC<-1 & adj.P.Val<p.val.cutoff][1:n], top_20_dge_out[logFC>1 & adj.P.Val<p.val.cutoff][1:n])
  return(top_20_dge_out)
}

###SECTION OUTPUT
kable(top_20_dge_retreiver(DT_efit, 10, 1e-6), align="c", col.names = rep(c("Gene", "log2(fold change)", "P-value (adjusted)"), 2))

```

***

#Gene Ontology and KEGG Enrichment Analysis

**Gene Ontology (GO):** A major bioinformatics initiative which offers a computational representation of the biological function of genes at molecular, cellular and tissue level. This tool enables one to annotate genes with their function. 

**KEGG (Kyoto Encyclopedia of Genes and Genomes):** KEGG pathway are manually drawn pathway maps which represent the current knowledge within metabolism, cellular processes and many more.  

**Table 4. GO terms and KEGG pathways using FDR<1e-6**

```{r echo=F, warning=F, message=F, error=F,fig.width=17, fig.height=7}
#1. Getting ENTREZ IDs for all genes in the filtered read count matrix 
entrez_ID <- suppressMessages(data.table(OrganismDbi::select(Mus.musculus, keys=DT_read_count_filtered[,as.character(ENSEMBL_ID)], columns="ENTREZID", keytype = "ENSEMBL")))
#2. Removing duplicates
entrez_ID <- entrez_ID[!duplicated(ENSEMBL)]
#3. Gene ontology enrichment analysis
DT_GO <- goana(DT_efit, coef=1, geneid = entrez_ID[,as.character(ENTREZID)], FDR=1e-6, species="Mm")
DT_GO_top <- data.table(topGO(DT_GO, sort="down", n=10))
#4. KEGG pathway enrichment analysis
DT_KEGG <- kegga(DT_efit, coef=1, geneid = entrez_ID[,as.character(ENTREZID)], FDR=1e-6, species="Mm")
DT_KEGG_top <- data.table(topKEGG(DT_KEGG, sort="down", n=10))

###SECTION OUTPUT
DT_GO_top[, `:=`(P.Down=format(P.Down, scientific=T, digits=2), P.Up=format(P.Up, scientific=T, digits=2))]
DT_KEGG_top[, `:=`(P.Down=format(P.Down, scientific=T, digits=2), P.Up=format(P.Up, scientific=T, digits=2))]

kable(data.table(Type="GO", DT_GO_top), align=c("l", "l", rep("c", 6)))
kable(data.table(Type="KEGG", DT_KEGG_top), align=c("l", "l", rep("c", 6)))

```

***

# Unsupervised Clustering 2

##Agglomerative hierarchical clustering with heat map

**Background:** Purpose of hierarchical clustering in combination with heatmap is to find subset of genes which explain the difference between study groups.

**Hierarchical clustering:** An unsupervised statistical learning method which aims at clustering the data in a not pre-determined amount of clusters. In agglomerative hierarchical clustering the tree is built from the terminal nodes (leaves) towards the root. A dendrogram is utilized to displayed the clusterings. A heatmap is added to the hierarchical clustering to enable the identification of gene clusters which might explain the  hierarchical clustering. 

**Fig 13. Hierarchical clustering of samples together with heatmap of significantly differentially expressed genes **

```{r echo=F, warning=F, message=F, error=F, fig.width=30, fig.height=30}
#1. Subsetting significant DE genes between MSC[SCI] and MSC[naive] 
DT_logFC <- data.table(toptable(DT_efit, coef=1, number=Inf, genelist=DT_read_count_filtered[, ENSEMBL_ID]))
DT_logFC <- merge(DT_logFC, DT_read_count[,.(ENSEMBL_ID, SYMBOL)], by.x="ID", by.y="ENSEMBL_ID")
DT_logFC_significant <- DT_logFC[adj.P.Val<1e-6]
setcolorder(DT_logFC_significant, c(1, 7, 2:6))
DT_logFC_significant[,"SYMBOL"] <- DT_logFC_significant[,.(ifelse(is.na(SYMBOL), ID, SYMBOL))]

#2. Retrieving the most significant genes from the log CPM matrix (i.e. heatmap is constructed using log CPM values)
DT_logFC_significant_lcpm <- DT_lcpm[DT_lcpm[,ENSEMBL_ID] %in% DT_logFC_significant[,ID]]

#3. Heatmap function
heatmap_plot_function <- function(heatmap.data, col.height, column.labels, dendrogram.setting, row.labels){
    heatmap.data <- data.matrix(heatmap.data)
    heatmap_plot_out <- heatmap.2(heatmap.data,
            scale="row",
            trace="none",
            density.info="none",
            dendrogram=dendrogram.setting,
            key=F,
            
            col=bluered(12),
            labRow = " ",
            labCol= column.labels,
            cexCol = 3,
            cexRow = 0.5,
            offsetRow = 0.1,
            offsetCol = 0.1,
            
            lhei=c(col.height,10),
            lwid=c(0.5,3))
  
    invisible(heatmap_plot_out)  
}

#4. Calculating p-value for hierarchical clustering
DT_hierarchical_clust <- data.matrix(DT_logFC_significant_lcpm[,3:length(DT_logFC_significant_lcpm)])
colnames(DT_hierarchical_clust) <- paste(DT_meta_data[,group]," ","(", DT_meta_data[,ID], ")", sep="")
DT_hierarchical_clust_boot <- pvclust(DT_hierarchical_clust, quiet=T)

###SECTION OUTPUT
heatmap_plot_function(DT_logFC_significant_lcpm[, 3:length(DT_logFC_significant_lcpm)], 2, DT_meta_data[,group], "both", DT_logFC_significant_lcpm[, as.character(ifelse(is.na(SYMBOL), ENSEMBL_ID, SYMBOL))])

# #Saving
# jpeg('heatmap.jpg',
#      width=2000,
#      height=2000,
#      quality=1000)
# heatmap_plot_function(DT_logFC_significant_lcpm[,c(3:14)],2,DT_meta_data[,sample],"both", DT_logFC_significant_lcpm[,as.character(ifelse(is.na(SYMBOL), ENSEMBL_ID, SYMBOL))])
# 
# dev.off()

```

**Fig 14.** _Figure reports a heatmap with hierarchical clustering (indicated with dendrograms) using log-CPM values. Only significantly differentially expressed genes are included (and genes with NA symbols were removed)._ 

```{r echo=F, warning=F, message=F, error=F, fig.width=7, fig.height=10}
invisible(dev.off())
#1. Retrieving data from heatmap
heatmap_data <- heatmap_plot_function(DT_logFC_significant_lcpm[, 3:length(DT_logFC_significant_lcpm)], 2, DT_meta_data[,group], "both", DT_logFC_significant_lcpm[, as.character(ifelse(is.na(SYMBOL), ENSEMBL_ID, SYMBOL))])
#2. Changing column order to match heatmap layout
DT_logFC_significant_lcpm_heatmap <- setcolorder(DT_logFC_significant_lcpm[,3:length(DT_logFC_significant_lcpm)], heatmap_data$colInd)
DT_logFC_significant_lcpm_heatmap <- cbind(DT_logFC_significant_lcpm[, c(1,2)], DT_logFC_significant_lcpm_heatmap)
#3. Changing row order to match heatmap layout
DT_logFC_significant_lcpm_heatmap <- DT_logFC_significant_lcpm_heatmap[, row_sort_temp:=heatmap_data$rowInd]
DT_logFC_significant_lcpm_heatmap <- DT_logFC_significant_lcpm_heatmap[order(row_sort_temp)]
DT_logFC_significant_lcpm_heatmap[, row_sort_temp:=NULL]
#4. Identifying the significant clusters using manual inspection for every k-addition
h <- heatmap(as.matrix(DT_logFC_significant_lcpm[,3:length(DT_logFC_significant_lcpm)]), keep.dendro=TRUE)
row.clusters <- as.hclust(h$Rowv)
row.clusters <- cutree(row.clusters, k=13)
cluster_index <- c(rep(1, 562), rep(2, 848), rep(3, 496), rep(4, 141), rep(5, 64), rep(6, 937), rep(7,66))
#5. Adding cluster belonging
DT_logFC_significant_lcpm_heatmap[,cluster:=cluster_index]
#6. Cluster analysis
cluster2 <- merge(DT_logFC_significant_lcpm_heatmap[cluster==2, "SYMBOL"], DT_mean_difference[, .(ID, logFC, adj.P.Val)], by.x="SYMBOL", by.y="ID")
cluster2 <- cluster2[order(adj.P.Val)]

###SECTION OUTPUT
kable(data.table(cluster2[order(logFC)][1:10][,`:=`(logFC=round(logFC, 2), adj.P.Val=format(adj.P.Val, scientific=T, digits=2))], cluster2[order(-logFC)][1:10][,`:=`(logFC=round(logFC, 2), adj.P.Val=format(adj.P.Val, scientific=T, digits=2))]), align="c")

```

**Fig .**
```{r echo=F, warning=F, message=F, error=F, fig.width=5, fig.height=5}
#1. Creating color palettes for chord diagram
chord_palette_group <- brewer.pal(11, "RdBu")
chord_palette_cluster <- brewer.pal(11, "BrBG")
#2. Creating data frame for chor diagram plotting
chord_data <- data.frame(group=c(rep("SCI", 3), rep("naive", 3), rep("invitro", 4)), cluster=c(rep(c(2,4,6), 2), c(1,3,5,7)))
names(chord_data) <- c("group", "cluster")
chord_data <- matrix(with(chord_data, table(group, cluster)), ncol=7)
colnames(chord_data) <- paste(rep("C", 7), 1:7, sep=":") 
rownames(chord_data) <- c("In vitro", "Naive", "SCI")

#3. Chord diagram plot
grid_col <- c(`In vitro` = color_palette[1], 
              Naive = color_palette[3], 
              SCI = color_palette[2],
              `C:1` = chord_palette_cluster[10], 
              `C:2` = chord_palette_cluster[8], 
              `C:3` = chord_palette_cluster[10], 
              `C:4` = chord_palette_cluster[8], 
              `C:5` = chord_palette_cluster[10], 
              `C:6` = chord_palette_cluster[8], 
              `C:7`=chord_palette_cluster[10])

circos.par(gap.after = c(rep(5, nrow(test)-1), 15, rep(5, ncol(test)-1), 15))

par(cex = 2, mar = c(0, 0, 0, 0))
chordDiagram(test, 
             transparency = 0.4, 
             grid.col = grid_col, 
             annotationTrackHeight = convert_height(c(1, 0.7), "mm"),
             directional = 1, 
             direction.type = c("arrows"),
             link.arr.type = "big.arrow",
             link.sort = TRUE, 
             link.decreasing = FALSE,
             link.rank = rank(test),
             annotationTrack = c("name","grid"))
circos.clear()

```

**Fig ** _figure text_

## Multiscale bootstrap resampling of agglomerative hierarchical clustering

**Fig 15. Multiscale bootstrap resampling of hierarchical clustering **

```{r echo=F, warning=F, message=F, error=F, fig.width=15, fig.height=7}
plot(DT_hierarchical_clust_boot, print.pv=T, float=-0.02, col.pv=c("darkred", "darkblue"), cex.pv=0.9, font.pv=2, print.num=F, main="", sub="", xlab="")
pvrect(DT_hierarchical_clust_boot)
```

**Fig 15.** _Figure reports hierarchical clustering using multiscale boostrap resampling with 1000 replicates. Numbers with red color are the approximately unbiased (AU) p-values while blue numbers represent bootstrap probability (BP). AU >95 and BP >70 are considered to be significant clusters. Red boxes indicate clusters with AU >95._

***

# Gene Set Testing

##Molecular Signatures Database

**Camera:** Performs a competitive gene set test which accounts for inter-gene correlations. Camera evaluates if a set of genes is highly ranked relative to other genes in terms of differential expression.  

**Barcode plot:** This function plots two sets of genes in a ranked list of statistics. Statistics are ranked left to right from smallest to largest. Shaded region in the middle of the plot represents the ranked statistics while the vertical bars reports the positions of the specified subsets. The enrichment worm (line) shows the relative enrichment of the vertical bars in each part of the plot.  

```{r echo=F, warning=F, message=F, error=F, fig.width=12, fig.height=6}
#1. Defining function which takes a specified index and runs the 'camera' function and returns a data_table
# camera_function <- function(selected.index, type){
#   data_out <- camera(DT_voom_raw, index=selected.index, design=DT_design, contrast = DT_contrast[,1], inter.gene.cor = 0.01)
#   data_out <- data.table(GeneSet = rownames(data_out), Library=type, data_out)[,!"FDR"][,PValue:=format(PValue, digits=2, scientific=T)]
#   setkey(data_out, GeneSet)  
#   return(data_out)}

# #2. Creating indices
# #C2
# load(url("http://bioinf.wehi.edu.au/software/MSigDB/mouse_c2_v5p1.rdata"))
# geneset_index_c2 <- ids2indices(Mm.c2,id=rownames(DT_read_count_filtered)) 
# #C5
# load(url("http://bioinf.wehi.edu.au/software/MSigDB/mouse_c5_v5p2.rdata"))
# geneset_index_c5 <- ids2indices(Mm.c5,id=rownames(DT_read_count_filtered)) 
# #C7
# load(url("http://bioinf.wehi.edu.au/software/MSigDB/mouse_c7_v5p2.rdata"))
# geneset_index_c7 <- ids2indices(Mm.c7,id=rownames(DT_read_count_filtered)) 
# #Hallmark
# load(url("http://bioinf.wehi.edu.au/software/MSigDB/mouse_H_v5p2.rdata"))
# geneset_index_hallmark <- ids2indices(Mm.H,id=rownames(DT_read_count_filtered)) 

#Selected and significant gene set from each 'library'
# c2_selected <- c()
# 
# c7_selected <- c()
# 
# hallmark_selected <- c()

####SECTION OUTPUT
# kable(rbind(camera_function(geneset_index_c2, "C2")[c2_selected], camera_function(geneset_index_c7, "C7")[c7_selected], camera_function(geneset_index_hallmark, "Hallmark")[hallmark_selected]), align = c("l", rep("c",4)), col.names = c("Gene set", "MSigDB","Genes (n)", "Direction", "P-value"))

```

```{r echo=F, warning=F, message=F, error=F, fig.width=12, fig.height=6}
#1. Bar code plot for M1-M2 up and down (from C2)

# barcodeplot(DT_efit$t[,1], index = geneset_index_c2$COATES_MACROPHAGE_M1_VS_M2_UP, index2=geneset_index_c2$COATES_MACROPHAGE_M1_VS_M2_DN, main="M1/M2", cex.main=2)

# jpeg('barcode_m1_m2.jpg',
#      width=750,height=400, quality=1000)

```

#Summary

**1. Annotation:** _Genes are annotated with gene name using their respective ENSEMBL ID._  
**2. Transformation:** _Read count matrix is transformed into log-CPM using original library sizes._  
**3. Filtering:** _Read count matrix is filtered using log-CPM values (>0 for at least 3 samples)._    
**4. Normalization:** _Effective library sizes are calculated using the library sizes for the filtered read count matrix and the trimmed mean of M values (TMM) approach._    
**5. Transformation:** _Filtered read count matrix is transformed into log-CPM matrix._    
**6. PCA:** _Conducted for the 500 genes with highest variance. Proportional variance explained, MDS and loading plots are created._    
**7. Design matrix:** _A dummy matrix which indicates which group each sample belongs._  
**8. Contrast matrix:** _Contrasts are the group comparisons of interest._    
**9. Voom transformation:** _Estimate precision weights for linear modelling to remove dependency between the variance and trhe mean._  
**10. Linear modelling:** _Linear modelling using precision weights followed by an empirical Bayes moderation._  
**11. Differentially expressed genes:** _Moderated t-statistics are used for determining significantly expressed genes for each contrast. Results are displayed with venn diagrams, mean-difference -and volcano plot and a summary table._  
**12. Analysis/interpretation:** _Using hierarchical clustering, heatmap, gene ontology and KEGG enrichment analysis and gene set analysis the difference between the study groups is sought for._   

# Bibliography

**[1]** _R Core Team (2016). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL htts://www.R-project._

**[2]** _Ritchie, M.E., Phipson, B., Wu, D., Hu, Y., Law, C.W., Shi, W., and Smyth, G.K. (2015). limma powers differential expression analyses for RNA-sequencing and microarray studies. Nucleic Acids Research 43(7), e47._

**[3]** _Robinson MD, McCarthy DJ and Smyth GK (2010). edgeR: a Bioconductor package for differential expression analysis of digital gene expression data. Bioinformatics 26, 139-140_

**[4]** _Law CW, Alhamdoosh M, Su S et al. RNA-seq analysis is easy as 1-2-3 with limma, Glimma and edgeR [version 1; referees: 3 approved]. F1000Research 2016, 5:1408._

# Setup

This analysis was conducted on:

```{r echo=T, warning=F, message=F, error=F}
sessionInfo()
```
